# 分布式数据一致性

## CAP理论

CAP理论，指的是在一个分布式系统中，Consistency(一致性)、Availability(可用性)、Partition Tolerance(分区容错性)，不能同时成立。

*Consistency* : Every read receives the most recent write or an error
*Availability* : Every request receives a (non-error) response – without the guarantee that it contains the most recent write
*Partition tolerance* : The system continues to operate despite an arbitrary number of messages being dropped (or delayed) by the network between nodes

①**一致性：**对于客户端的每次读操作，要么读到的是最新的数据，要么读取失败。换句话说，一致性是站在分布式系统的角度，对访问本系统的客户端的一种承诺：要么我给您返回一个错误，要么我给你返回绝对一致的最新数据，不难看出，其强调的是数据正确。

**数据一定是最新的，那么多个数据存储节点的数据就一定是一致的**

②**可用性：**任何客户端的请求都能得到响应数据，不会出现响应错误。换句话说，可用性是站在分布式系统的角度，对访问本系统的客户的另一种承诺：我一定会给您返回数据，不会给你返回错误，但不保证数据最新，强调的是不出错。

**在一定时间范围内，一定会返回一个数据结果，但不保证返回的是最新的**

③**分区容忍性：**由于分布式系统通过网络进行通信，网络是不可靠的。当任意数量的消息丢失或延迟到达时，系统仍会继续提供服务，不会挂掉。换句话说，分区容忍性是站在分布式系统的角度，对访问本系统的客户端的再一种承诺：我会一直运行，不管我的内部出现何种数据同步问题，强调的是不挂掉。



在不存在网络失败的情况下（分布式系统正常运行时），C和A能够同时保证。只有当网络发生分区或失败时，才会在C和A之间做出选择。

**由于P一定会发生，所以C、A不能够同时保证**

对于一个分布式系统而言，P是前提，必须保证，因为只要有网络交互就一定会有延迟和数据丢失，这种状况我们必须接受，必须保证系统不能挂掉。所以只剩下C、A可以选择。要么保证数据一致性（保证数据绝对正确），要么保证可用性（保证系统不出错）。

当选择了C（一致性）时，如果由于网络分区而无法保证特定信息是最新的，则系统将返回错误或超时。

当选择了A（可用性）时，系统将始终处理客户端的查询并尝试返回最新的可用的信息版本，即使由于网络分区而无法保证其是最新的。



## BASE理论

BASE 理论是对 CAP 中的一致性和可用性进行一个权衡的结果，理论的核心思想就是：我们无法做到强一致，但每个应用都可以根据自身的业务特点，采用适当的方式来使系统达到最终一致性。

BASE理论是Basically Available(基本可用)，Soft State（软状态）和Eventually Consistent（最终一致性）三个短语的缩写。

弱一致性、最终一致性



BASE理论的内容

基本可用（Basically Available）软状态（Soft State）最终一致性（Eventually Consistent）下面展开讨论：

### 1.基本可用

什么是基本可用呢？假设系统，出现了不可预知的故障，但还是能用，相比较正常的系统而言：

**响应时间上的损失**：正常情况下的搜索引擎0.5秒即返回给用户结果，而基本可用的搜索引擎可以在2秒作用返回结果。**功能上的损失**：在一个电商网站上，正常情况下，用户可以顺利完成每一笔订单。但是到了大促期间，为了保护购物系统的稳定性，部分消费者可能会被引导到一个降级页面。

### 2.软状态

什么是软状态呢？相对于原子性而言，要求多个节点的数据副本都是一致的，这是一种“硬状态”。

软状态指的是：允许系统中的数据存在中间状态，并认为该状态不影响系统的整体可用性，即允许系统在多个不同节点的数据副本存在数据延时。

### 3.最终一致性

上面说软状态，然后不可能一直是软状态，必须有个时间期限。在期限过后，应当保证所有副本保持数据一致性，从而达到数据的最终一致性。这个时间期限取决于网络延时、系统负载、数据复制方案设计等等因素。

而在实际工程实践中，最终一致性分为5种：

#### 3.1. 因果一致性（Causal consistency）

因果一致性指的是：如果节点A在更新完某个数据后通知了节点B，那么节点B之后对该数据的访问和修改都是基于A更新后的值。于此同时，和节点A无因果关系的节点C的数据访问则没有这样的限制。

#### 3.2. 读己之所写（Read your writes）

读己之所写指的是：节点A更新一个数据后，它自身总是能访问到自身更新过的最新值，而不会看到旧值。其实也算一种因果一致性。

#### 3.3. 会话一致性（Session consistency）

会话一致性将对系统数据的访问过程框定在了一个会话当中：系统能保证在同一个有效的会话中实现 “读己之所写” 的一致性，也就是说，执行更新操作之后，客户端能够在同一个会话中始终读取到该数据项的最新值。

#### 3.4. 单调读一致性（Monotonic read consistency）

单调读一致性指的是：如果一个节点从系统中读取出一个数据项的某个值后，那么系统对于该节点后续的任何数据访问都不应该返回更旧的值。

#### 3.5. 单调写一致性（Monotonic write consistency）

单调写一致性指的是：一个系统要能够保证来自同一个节点的写操作被顺序的执行。



在实际的实践中，这5种系统往往会结合使用，以构建一个具有最终一致性的分布式系统。

实际上，不只是分布式系统使用最终一致性，关系型数据库在某个功能上，也是使用最终一致性的。比如备份，数据库的复制过程是需要时间的，这个复制过程中，业务读取到的值就是旧的。当然，最终还是达成了数据一致性。这也算是一个最终一致性的经典案例。

小结

总体来说BASE理论面向的是大型高可用、可扩展的分布式系统。与传统ACID特性相反，不同于ACID的强一致性模型，BASE提出通过牺牲强一致性来获得可用性，并允许数据段时间内的不一致，但是最终达到一致状态。同时，在实际分布式场景中，不同业务对数据的一致性要求不一样。因此在设计中，ACID和BASE理论往往又会结合使用。

### 实际应用中的最终一致性方案

#### 1.提供查询服务，确认数据的状态



#### 2.借助本地事务原子性，插入异步通知表，定时任务抓取同步



#### 3.TCC事务补偿

- 简介
- - 2007年，Pat Helland发表了一篇名为《Life beyond Distributed Transactions: an Apostate’s Opinion》的论文，提出了TCC（Try-Confirm-Cancel） 的概念。
  - 两阶段提交（2PC）和三阶段提交（3PC）并不适用于并发量大的业务场景。TCC事务机制相比于2PC、3PC，不会锁定整个资源，而是通过引入补偿机制，将资源转换为业务逻辑形式，锁的粒度变小。
  - TCC的核心思想是：针对每个操作，都要注册一个与其对应的确认和补偿（撤销）操作，分为三个阶段：
  - - Try：这个阶段对各个服务的资源做检测以及对资源进行锁定或者预留；
    - Confirm ：执行真正的业务操作，不作任何业务检查，只使用Try阶段预留的业务资源，Confirm操作要求具备幂等设计，Confirm失败后需要进行重试；
    - Cancel：如果任何一个服务的业务方法执行出错，那么这里就需要进行补偿，即执行回滚操作，释放Try阶段预留的业务资源 ，Cancel操作要求具备幂等设计，Cancel失败后需要进行重试

例如：电商系统中有两个服务：订单服务A、库存服务B：对外提供服务时，必须接受一些不确定性，即对服务A/B的一次调用仅是一个临时性操作，服务消费方保留了后续的取消权。如果消费方认为全局事务应该rollback，它会要求取消之前的临时性操作；如果消费方认为全局事务应该commit时，它会进行的一个确认操作。



- Try
- - Try阶段一般用于锁定某个资源，设置一个预备状态或冻结部分数据。对于示例中的每一个服务，Try阶段所做的工作如下：
  - - 订单服务：先置一个中间状态“UPDATING”，而不是直接设置“支付成功”状态；
    - 库存服务：先用一个冻结库存字段保存冻结库存数，而不是直接扣掉库存；
    - 积分服务：预增加会员积分；
    - 仓储服务：创建销售出库单，但状态是UNKONWN。
- Confirm
- - 根据Try阶段的执行情况，Confirm分为两种情况：
  - - 理想情况下，所有Try全部执行成功，则执行各个服务的Confirm逻辑；
    - 部分服务Try执行失败，则执行第三阶段——Cancel。
  - Confirm阶段一般需要各个服务自己实现Confirm逻辑：
  - - 订单服务：confirm逻辑可以是将订单的中间状态变更为PAYED-支付成功；
    - 库存服务：将冻结库存数清零，同时扣减掉真正的库存；
    - 积分服务：将预增加积分清零，同时增加真实会员积分；
    - 仓储服务：修改销售出库单的状态为已创建-CREATED。
- Confirm阶段的各个服务本身可能出现问题，这时候一般就需要TCC框架了（比如ByteTCC，tcc-transaction，himly），TCC事务框架一般会记录一些分布式事务的活动日志，保存事务运行的各个阶段和状态，从而保证整个分布式事务的最终一致性。
- Cancel
- - 如果Try阶段执行异常，就会执行Cancel阶段。比如：对于订单服务，可以实现的一种Cancel逻辑就是：将订单的状态设置为“CANCELED”；对于库存服务，Cancel逻辑就是：将冻结库存扣减掉，加回到可销售库存里去。
- - - 许多公司为了简化TCC的使用，通常会将一个服务的某个核心接口拆成两个，比如库存服务的扣减库存接口，拆成两个子接口：①扣减接口 ②回滚扣减库存接口，由TCC框架来保证当某个接口执行失败后去执行对应的rollback接口。
- 总结
- - 从正常的流程上讲，TCC仍然是一个两阶段提交协议。但是，在执行出现问题的时候，有一定的自我修复能力，如果任何一个事务参与者出现了问题，协调者可以通过执行逆操作来取消之前的操作，达到最终的一致状态（比如冲正交易、查询交易）。
  - 从TCC的执行流程也可以看出，服务提供方需要提供额外的补偿逻辑，那么原来一个服务接口，引入TCC后可能要改造成3种逻辑：
  - - Try：先是服务调用链路依次执行Try逻辑；
    - Confirm：如果都正常的话，TCC分布式事务框架推进执行Confirm逻辑，完成整个事务；
    - Cancel：如果某个服务的Try逻辑有问题，TCC分布式事务框架感知到之后就会推进执行各个服务的Cancel逻辑，撤销之前执行的各种操作。
  - 注意：在设计TCC事务时，接口的Cancel和Confirm操作都必须满足幂等设计。
  - 框架选型
  - - TCC框架的可供选择余地比较少，目前相对比较成熟的是阿里开源的分布式事务框架seata（[https://github.com/seata/seata](https://link.zhihu.com/?target=https%3A//github.com/seata/seata)），这个框架是经历过阿里生产环境的大量考验，同时也支持dubbo、spring cloud。
  - 优点
  - - 跟2PC比起来，实现以及流程相对简单了一些，但数据的一致性比2PC也要差一些，当然性能也可以得到提升。
  - 缺点
  - - TCC模型对业务的侵入性太强，事务回滚实际上就是自己写业务代码来进行回滚和补偿，改造的难度大。一般来说支付、交易等核心业务场景，可能会用TCC来严格保证分布式事务的一致性，要么全部成功，要么全部自动回滚。这些业务场景都是整个公司的核心业务有，比如银行核心主机的账务系统，不容半点差池。
    - 但是，在一般的业务场景下，尽量别没事就用TCC作为分布式事务的解决方案，因为自己手写回滚/补偿逻辑，会造成业务代码臃肿且很难维护。

#### 4.可靠性消息的最终一致性

如rocketmq的半消息 + 事务回查

#### 5.定期校对





# 分布式事务

保证关系型数据库分布式数据一致性

## XA

XA协议由Tuxedo首先提出的，并交给X/Open组织，作为[资源管理器](https://baike.baidu.com/item/资源管理器/1951545)（数据库）与[事务](https://baike.baidu.com/item/事务)管理器的接口标准。[Oracle](https://baike.baidu.com/item/Oracle/301207)、[Informix](https://baike.baidu.com/item/Informix/269954)、[DB2](https://baike.baidu.com/item/DB2/7034285)和[Sybase](https://baike.baidu.com/item/Sybase/2138155)等各大数据库厂家都提供对XA的支持。XA协议采用两阶段提交方式来管理[分布式事务](https://baike.baidu.com/item/分布式事务/4747029)。XA接口提供资源管理器与事务管理器之间进行通信的标准接口。XA协议包括两套函数，以xa_开头的及以ax_开头的。

二阶提交

#### AP

应用程序。比如我们的JAVA应用

#### TM

事务协调者。比如我们的SEATA框架

#### RM

资源管理者。比如Mysql、Oracle



### Mysql

mysql支持XA协议文档https://dev.mysql.com/doc/refman/8.0/en/xa.html

#### 13.3.8.1 XA Transaction SQL Statements

To perform XA transactions in MySQL, use the following statements:

```sql
#第一阶段
#开启一个xid的事务
XA {START|BEGIN} xid [JOIN|RESUME]
#执行sql语句
#结束一个xid的事务
XA END xid [SUSPEND [FOR MIGRATE]]
#向TM表明已经准备好了
XA PREPARE xid

#第二阶段
#提交事务
XA COMMIT xid [ONE PHASE]
#回滚事务
XA ROLLBACK xid

XA RECOVER [CONVERT XID]
```



例子如下，两个不同机器上的mysql数据库为例

oms_db

```sql
XA START 'TEST01';
INSERT INTO `oms_db`.`oms_order_main` ...
XA END 'TEST01';
XA PREPARE 'TEST01';

##由TM来决定，事务是该提交还是回滚
XA ROLLBACK 'TEST01';
```

order_main

```sql
XA START 'TEST02';
INSERT INTO order_main ...
XA END 'TEST02';
XA PREPARE 'TEST02';

##由TM来决定，事务是该提交还是回滚
XA ROLLBACK 'TEST02';
```

**TM先开启为每一个RM开启事务，RM执行结束后，根据每个RM的执行结果，来决定全局的、也就是第二阶段的提交或回滚**

那么，如果在第二阶段，一个RM执行COMMIT成功了，但是另一个RM执行COMMIT失败了，数据结果和我们预期的还是不一致，那该怎么办呢？？？这是TM需要解决的问题，比如SEATA，后续探究一下



### JTA

JTA，即Java Transaction API，JTA允许应用程序执行分布式事务处理——在两个或多个网络计算机资源上访问并且更新数据。[JDBC](https://baike.baidu.com/item/JDBC)[驱动程序](https://baike.baidu.com/item/驱动程序)的JTA支持极大地增强了数据访问能力。

Java提供了基于XA的应用程序执行分布式事务处理

如rt.jar->javax.sql.XAConnection、XADataSource   javax.transaction.xa.Xid

不同的数据库厂商的实现，比如mysql

```
com.mysql.cj.jdbc.MysqlXAConnection
```



Java虽然提供了相应的实现规范接口，但是如果我们自己实现还是需要考虑比如第二阶段的完全成功，所以引出已经成熟的分布式事务框架如Atomikos、Bitronix、Seata



## Seata

### AT模式



### TCC模式



### SAGA模式



### XA模式





# Redis

1kb等于1024字节

1字节8比特位

分布式缓存

C语言写的

0-15 16个分区

单线程、无线程安全问题

### 五种数据类型

#### String

可以存储 字符串、整数、浮点

整数：可以使用incr()原子递增

##### 实战：1.作计数器，比如修改订单状态里，妥投和拒收两种状态可以相互更改，修改状态成功后，需要处理后续得流程，比如妥投要推结算，三方订单妥投或拒收要mq发送给三方系统，使用incr()，可以作幂等、可以作并发控制   

String类型在Redis底层是使用什么数据结构存储的？

答： int / SDS int存储整型，SDS存储字符和浮点

C语言的字符无法存储二进制，存储字符串'\0'结尾 如果字符串里含有空格 那么空格后面的字符将不会被识别

所以使用SDS sdshdr8  默认长度2^8 - 1  sdshdr 5、8、16、32、64

##### 应用场景：Session共享、keyvalue的缓存比如订单里有春播卡展示卡号

#### List

Redis底层是如何存储来实现这种数据类型的？

redis3.2之前使用的是LinkedList（双向链表，内存占用多，插入删除快）和ZipList（存储元素个数少或者长度短，使用压缩链表、连续内存、占用少，插入删除稍慢）

redis3.2开始使用quickList（基于ZipList的双向链表）

quickListNode{

```
	prev;

	next;

	zipList;// 压缩存储空间，提高存储效率这是list（entry1、entry2）
```

}

##### 应用场景：消费队列（左进右出）、栈（左进左出）

#### Hash

key -> value( filed -> value;filed -> value;filed -> value;) 

也是使用链表解决hash碰撞的

##### 应用场景：宅急送快递推tms时，每一天要为其生成一个批次交接单，交接单对象用Map存储

#### Set

不可重复、无序

##### 应用场景：每日单独成箱质检录入爆品、一堆Sku要Set

Redis底层是如何存储来实现这种数据类型的？

intSet hashTable

如果使用hashTable时，只是用key做存储，value是空的

intset只存储整数类型，使用数组顺序存储，查找二分查找

#### SortedSet

key -> value( score -> value )

可以通过score作排序

Redis底层是如何存储来实现这种数据类型的？

ziplist 或者 skiplist + hashtable

##### 应用场景：需要存排名

### 过期时间

像库房详情warehouse这种redis缓存，不需要设置过期时间

其余绝大多数场景都需要设置过期时间

expire(key, 过期时间);

setex(key ,value, 过期时间)

ttl命令查看剩余过期时间

persist 对key持久化 不需要过期了

**删除过期的key的策略**

1.消极方法：

已经过期了，再一次读取的时候会删除

2.积极方法：周期性的从设置了过期时间的key中选择一部分的key进行删除

  (1)随机测试20个带有超时时间的key

  (2) 如果超过25%的key被删除，则重复执行整个流程

### Rdis内存回收策略

当内存达到一定大时，淘汰一些对象

redis.conf

maxmemory-policy 默认是noeviction直接报错

allkeys-lru 所有的key（设置过期时间和没设置过期时间都算上）最少使用的数据淘汰

allkeys-random 所有的key随机淘汰

volatile-random（随机）/lru（最少使用）/ttl（即将过期） 以上都是设置了过期时间的

### Redis为什么单线程性能却很高？

redis的限制在于：内存和网络带宽

性能高是因为使用到了多路复用

### Redis持久化

1.使用redis作Nosql数据库

2.redis出现故障，快速恢复redis

#### RDB（快照）默认、AOF（事务日志）

RDB:当符合【条件】时，会fork一个子进程  生成dump.rdb文件 进行io操作

条件有4种：1.配置规则 redis.conf  save seconds changes  或的关系

```
														 save 900 1

														 save 300 10

														 save 60 10000

				 2.客户端主动save（阻塞所有来自客户端的请求）或者bgsave（异步后台备份）

                 3.客户端flushall 

                4.执行复制操作 master-slave
```

缺点：两次快照的间隔 会出现数据丢失

AOF：事务操作追加到文件、像实时日志一样、记录所有事务行为。效率会低

redis.conf   Append Only no  改为yes 开启

redis支持两种模式同时存在，但是AOF的优先级更高，启动时会直接加载AOF文件

AOF很大的时候会重写，fork子进程重写，重写的过程中，把后续的指令再记录，再合并

操作系统缓存刷到硬盘 默认是1s

dump.rdb 或者 appendonly.aof文件 在服务器启动时 会自动加载到redis里

### Redis的Lua脚本

eval 执行lua脚本

### 发布订阅

pub / sub

Bloomfilter单点内，分布式情况下的新增或删除如何通知到其他节点

## 分布式Redis

### 主从

从节点redis.conf  配置salveof 主ip 主port

主节点宕机后，无法选出新的主节点

Redis中使用外部的哨兵节点帮助Redis主从选主

### 哨兵

1.监控master slave健康情况

2.当master出现故障时，从slave选举一个新的master

#### 哨兵也要作集群

哨兵之间不需要做配置，使用节点订阅pub/sub，订阅redis集群主节点来了解彼此

哨兵集群也要有选leader，使用raft算法

### Cluster

分片用的，一般3个分片，并且对3个分片做salve

### 分布式锁

setnx 不能重复

setnx返回1 设置成功

expire设置带超时时间的

### 缓存雪崩

**现象**：大量key同一时间点失效，同时又有大量请求打进来，导致流量直接打在DB上，造成DB不可用。

**解决方案**：

1.设置key永不失效（热点数据）；

2.设置key缓存失效时候尽可能错开；乘以随机数

3.使用多级缓存机制，比如同时使用redsi和memcache缓存，请求->redis->memcache->db；

### 缓存穿透

Redis和DB都不存在

- 从DB中查询出来数据为空，也进行空数据的缓存，避免DB数据为空也每次都进行数据库查询；
- 使用布隆过滤器，但是会增加一定的复杂度及存在一定的误判率；

前端 调用  wms return 实物库存 - 占用数

把仓库 + 商品id + lot 存入布隆过滤器中

### 缓存击穿

击穿了redis，但是数据库存在

某一时刻对同一个key有大量的并发请求进来，这时候会出现请求打到数据库层面

解决方案：

1.加分布式锁，对于同一个key，访问redis时加分布式锁，那么大并发情况下，只有一个线程会拿到锁，读DB并且写入缓存，后续排队的线程就可以从缓存中读取了

2.热点数据不过期

和雪崩的区别在于，雪崩是同一时刻大批量key失效，而击穿是指某一个key失效后多个并发访问



### 数据库与Redis的数据一致性

无法实现强一致性

#### 最终一致的实现

##### 先删除Redis再更新数据库

如果redis删除失败则抛出异常，innodb事务回滚。不会出现问题

如果redis删除成功，但是更新mysql失败，再次读取redis时发现不存在会读数据库，读到的一定是最新的。不会出现问题

**此种处理方式看起来并不会出现数据一致性的问题，但是先删除redis值成功时的临界点，可能出现并发问题导致一致性问题**

线程A先删除redis成功，线程B读取redis为空，则读数据库，读到的是线程A还未更新操作的值(线程A所认为的旧值，而不是线程A所预期的最新值)，线程A再更新数据库成功，但此时redis上的值是不准确的

该问题需要加分布式锁来保证，线程A删除redis与更新数据库操作需要被分布式写锁包裹住，线程B读取需要被分布式读锁包裹住

#### 先更新数据库再更新Redis

如果更新数据库失败，则事务回滚。不会出现问题

如果更新数据库成功，再删除redis失败，此时需要保证一致性，可以采用重试机制

​		1.MQ重试，RocketMQ和Mysql可以保证最终一致性，消费端删除redis来达到Mysql与Redis的最终一致

​		2.本地表重试，删除redis的操作表与Mysql的事务表放到一个事务提交。redis操作表job重试（1s一次也会延			迟1s，容忍的情况可以使用）

​		3.借助mysql的Binlog，比如Canal框架，更新Redis，优解，因为即满足了一定的实时性，又不侵入业务











# 幂等

在编程中一个幂等操作的特点是其任意多次执行所产生的影响均与一次执行的影响相同

## 保证幂等性的方案

### Redis

1.不存在并发的场景。比如消息的消费

```java
// 发送端代码
// 生成一个唯一ID，例如时间戳，或UUID或token
String uid = UUID...;
Message message = new Message(消息体中附带uid);

// 消费端代码
// 检查消息是否消费过
String val = redisTemplate.get(KEY_PREFIX + UID);
if (val != null) {return "success"};
// 执行本地事务
begin transaction;
// 执行成功后将消息中的uid写入到redis中
redisTemplate.set(KEY_PREFIX + UID);
```

2.存在并发的场景。这种一般是异常情况，同一时刻客户端发送了多次相同的请求。需要加层分布式锁

```java
// 客户端代码
// 生成一个唯一ID，例如时间戳，或UUID
String uid = UUID...;
Message message = new Message(消息体中附带uid);

// 服务端代码
redisTemplate.lock();
// 检查消息是否消费过
String val = redisTemplate.get(KEY_PREFIX + UID);
if (val != null) {return "success"};
// 执行本地事务
begin transaction;
// 执行成功后将消息中的uid写入到redis中
redisTemplate.set(KEY_PREFIX + UID);
redisTemplate.unlock();
```

### 数据库

1.数据库的唯一约束。UNQUE_KEY  insert 抛出DuplicateKeyException。

比如业务上天然的唯一键如orderId skuId

非天然的。服务端创建一个消息表，基于消息生成MD5作为唯一键做插入，插入成功则处理，异常则认为被幂等校验了

