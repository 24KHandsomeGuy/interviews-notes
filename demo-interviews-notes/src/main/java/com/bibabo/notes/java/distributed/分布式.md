# 分布式数据一致性

## CAP理论

CAP理论，指的是在一个分布式系统中，Consistency(一致性)、Availability(可用性)、Partition Tolerance(分区容错性)，不能同时成立。

*Consistency* : Every read receives the most recent write or an error
*Availability* : Every request receives a (non-error) response – without the guarantee that it contains the most recent write
*Partition tolerance* : The system continues to operate despite an arbitrary number of messages being dropped (or delayed) by the network between nodes

①**一致性：**对于客户端的每次读操作，要么读到的是最新的数据，要么读取失败。换句话说，一致性是站在分布式系统的角度，对访问本系统的客户端的一种承诺：要么我给您返回一个错误，要么我给你返回绝对一致的最新数据，不难看出，其强调的是数据正确。

**数据一定是最新的，那么多个数据存储节点的数据就一定是一致的**

②**可用性：**任何客户端的请求都能得到响应数据，不会出现响应错误。换句话说，可用性是站在分布式系统的角度，对访问本系统的客户的另一种承诺：我一定会给您返回数据，不会给你返回错误，但不保证数据最新，强调的是不出错。

**在一定时间范围内，一定会返回一个数据结果，但不保证返回的是最新的**

③**分区容忍性：**由于分布式系统通过网络进行通信，网络是不可靠的。当任意数量的消息丢失或延迟到达时，系统仍会继续提供服务，不会挂掉。换句话说，分区容忍性是站在分布式系统的角度，对访问本系统的客户端的再一种承诺：我会一直运行，不管我的内部出现何种数据同步问题，强调的是不挂掉。



在不存在网络失败的情况下（分布式系统正常运行时），C和A能够同时保证。只有当网络发生分区或失败时，才会在C和A之间做出选择。

**由于P一定会发生，所以C、A不能够同时保证**

对于一个分布式系统而言，P是前提，必须保证，因为只要有网络交互就一定会有延迟和数据丢失，这种状况我们必须接受，必须保证系统不能挂掉。所以只剩下C、A可以选择。要么保证数据一致性（保证数据绝对正确），要么保证可用性（保证系统不出错）。

当选择了C（一致性）时，如果由于网络分区而无法保证特定信息是最新的，则系统将返回错误或超时。

当选择了A（可用性）时，系统将始终处理客户端的查询并尝试返回最新的可用的信息版本，即使由于网络分区而无法保证其是最新的。



### 扩展

CAP定理，又被叫作布鲁尔定理。对于设计分布式系统来说(不仅仅是分布式事务)的架构师来说，CAP就是你的入门理论。

- C (一致性):对某个指定的客户端来说，读操作能返回最新的写操作。对于数据分布在不同节点上的数据上来说，如果在某个节点更新了数据，那么在其他节点如果都能读取到这个最新的数据，那么就称为强一致，如果有某个节点没有读取到，那就是分布式不一致。
- A (可用性)：非故障的节点在合理的时间内返回合理的响应(不是错误和超时的响应)。可用性的两个关键一个是合理的时间，一个是合理的响应。合理的时间指的是请求不能无限被阻塞，应该在合理的时间给出返回。合理的响应指的是系统应该明确返回结果并且结果是正确的，这里的正确指的是比如应该返回50，而不是返回40。
- P (分区容错性):当出现网络分区后，系统能够继续工作。打个比方，这里个集群有多台机器，有台机器网络出现了问题，但是这个集群仍然可以正常工作。

熟悉CAP的人都知道，三者不能共有，如果感兴趣可以搜索CAP的证明，在分布式系统中，网络无法100%可靠，分区其实是一个必然现象，如果我们选择了CA而放弃了P，那么当发生分区现象时，为了保证一致性，这个时候必须拒绝请求，但是A又不允许，所以分布式系统理论上不可能选择CA架构，只能选择CP或者AP架构。

对于CP来说，放弃可用性，追求一致性和分区容错性，我们的zookeeper其实就是追求的强一致。

对于AP来说，放弃一致性(这里说的一致性是强一致性)，追求分区容错性和可用性，这是很多分布式系统设计时的选择，后面的BASE也是根据AP来扩展。

顺便一提，CAP理论中是忽略网络延迟，也就是当事务提交时，从节点A复制到节点B，但是在现实中这个是明显不可能的，所以总会有一定的时间是不一致。同时CAP中选择两个，比如你选择了CP，并不是叫你放弃A。因为P出现的概率实在是太小了，大部分的时间你仍然需要保证CA。就算分区出现了你也要为后来的A做准备，比如通过一些日志的手段，是其他机器回复至可用。

## BASE理论

BASE 理论是对 CAP 中的一致性和可用性进行一个权衡的结果，理论的核心思想就是：我们无法做到强一致，但每个应用都可以根据自身的业务特点，采用适当的方式来使系统达到最终一致性。

BASE理论是Basically Available(基本可用)，Soft State（软状态）和Eventually Consistent（最终一致性）三个短语的缩写。

弱一致性、最终一致性



BASE理论的内容

基本可用（Basically Available）软状态（Soft State）最终一致性（Eventually Consistent）下面展开讨论：

### 1.基本可用

什么是基本可用呢？假设系统，出现了不可预知的故障，但还是能用，相比较正常的系统而言：

**响应时间上的损失**：正常情况下的搜索引擎0.5秒即返回给用户结果，而基本可用的搜索引擎可以在2秒作用返回结果。

**功能上的损失**：在一个电商网站上，正常情况下，用户可以顺利完成每一笔订单。但是到了大促期间，为了保护购物系统的稳定性，部分消费者可能会被引导到一个降级页面。

### 2.软状态

什么是软状态呢？相对于原子性而言，要求多个节点的数据副本都是一致的，这是一种“硬状态”。

软状态指的是：允许系统中的数据存在中间状态，并认为该状态不影响系统的整体可用性，即允许系统在多个不同节点的数据副本存在数据延时。

### 3.最终一致性

上面说软状态，然后不可能一直是软状态，必须有个时间期限。在期限过后，应当保证所有副本保持数据一致性，从而达到数据的最终一致性。这个时间期限取决于网络延时、系统负载、数据复制方案设计等等因素。

而在实际工程实践中，最终一致性分为5种：

#### 3.1. 因果一致性（Causal consistency）

因果一致性指的是：如果节点A在更新完某个数据后通知了节点B，那么节点B之后对该数据的访问和修改都是基于A更新后的值。于此同时，和节点A无因果关系的节点C的数据访问则没有这样的限制。

#### 3.2. 读己之所写（Read your writes）

读己之所写指的是：节点A更新一个数据后，它自身总是能访问到自身更新过的最新值，而不会看到旧值。其实也算一种因果一致性。

#### 3.3. 会话一致性（Session consistency）

会话一致性将对系统数据的访问过程框定在了一个会话当中：系统能保证在同一个有效的会话中实现 “读己之所写” 的一致性，也就是说，执行更新操作之后，客户端能够在同一个会话中始终读取到该数据项的最新值。

#### 3.4. 单调读一致性（Monotonic read consistency）

单调读一致性指的是：如果一个节点从系统中读取出一个数据项的某个值后，那么系统对于该节点后续的任何数据访问都不应该返回更旧的值。

#### 3.5. 单调写一致性（Monotonic write consistency）

单调写一致性指的是：一个系统要能够保证来自同一个节点的写操作被顺序的执行。



在实际的实践中，这5种系统往往会结合使用，以构建一个具有最终一致性的分布式系统。

实际上，不只是分布式系统使用最终一致性，关系型数据库在某个功能上，也是使用最终一致性的。比如备份，数据库的复制过程是需要时间的，这个复制过程中，业务读取到的值就是旧的。当然，最终还是达成了数据一致性。这也算是一个最终一致性的经典案例。

小结

总体来说BASE理论面向的是大型高可用、可扩展的分布式系统。与传统ACID特性相反，不同于ACID的强一致性模型，BASE提出通过牺牲强一致性来获得可用性，并允许数据段时间内的不一致，但是最终达到一致状态。同时，在实际分布式场景中，不同业务对数据的一致性要求不一样。因此在设计中，ACID和BASE理论往往又会结合使用。

### 实际应用中的最终一致性方案

#### 1.提供查询服务，确认数据的状态



#### 2.借助本地事务原子性，插入异步通知表，定时任务抓取同步



#### 3.TCC事务补偿

- 简介
- - 2007年，Pat Helland发表了一篇名为《Life beyond Distributed Transactions: an Apostate’s Opinion》的论文，提出了TCC（Try-Confirm-Cancel） 的概念。
  - 两阶段提交（2PC）和三阶段提交（3PC）并不适用于并发量大的业务场景。TCC事务机制相比于2PC、3PC，不会锁定整个资源，而是通过引入补偿机制，将资源转换为业务逻辑形式，锁的粒度变小。
  - TCC的核心思想是：针对每个操作，都要注册一个与其对应的确认和补偿（撤销）操作，分为三个阶段：
  - - Try：这个阶段对各个服务的资源做检测以及对资源进行锁定或者预留；
    - Confirm ：执行真正的业务操作，不作任何业务检查，只使用Try阶段预留的业务资源，Confirm操作要求具备幂等设计，Confirm失败后需要进行重试；
    - Cancel：如果任何一个服务的业务方法执行出错，那么这里就需要进行补偿，即执行回滚操作，释放Try阶段预留的业务资源 ，Cancel操作要求具备幂等设计，Cancel失败后需要进行重试

例如：电商系统中有两个服务：订单服务A、库存服务B：对外提供服务时，必须接受一些不确定性，即对服务A/B的一次调用仅是一个临时性操作，服务消费方保留了后续的取消权。如果消费方认为全局事务应该rollback，它会要求取消之前的临时性操作；如果消费方认为全局事务应该commit时，它会进行的一个确认操作。



- Try
- - Try阶段一般用于锁定某个资源，设置一个预备状态或冻结部分数据。对于示例中的每一个服务，Try阶段所做的工作如下：
  - - 订单服务：先置一个中间状态“UPDATING”，而不是直接设置“支付成功”状态；
    - 库存服务：先用一个冻结库存字段保存冻结库存数，而不是直接扣掉库存；
    - 积分服务：预增加会员积分；
    - 仓储服务：创建销售出库单，但状态是UNKONWN。
- Confirm
- - 根据Try阶段的执行情况，Confirm分为两种情况：
  - - 理想情况下，所有Try全部执行成功，则执行各个服务的Confirm逻辑；
    - 部分服务Try执行失败，则执行第三阶段——Cancel。
  - Confirm阶段一般需要各个服务自己实现Confirm逻辑：
  - - 订单服务：confirm逻辑可以是将订单的中间状态变更为PAYED-支付成功；
    - 库存服务：将冻结库存数清零，同时扣减掉真正的库存；
    - 积分服务：将预增加积分清零，同时增加真实会员积分；
    - 仓储服务：修改销售出库单的状态为已创建-CREATED。
- Confirm阶段的各个服务本身可能出现问题，这时候一般就需要TCC框架了（比如ByteTCC，tcc-transaction，himly），TCC事务框架一般会记录一些分布式事务的活动日志，保存事务运行的各个阶段和状态，从而保证整个分布式事务的最终一致性。
- Cancel
- - 如果Try阶段执行异常，就会执行Cancel阶段。比如：对于订单服务，可以实现的一种Cancel逻辑就是：将订单的状态设置为“CANCELED”；对于库存服务，Cancel逻辑就是：将冻结库存扣减掉，加回到可销售库存里去。
- - - 许多公司为了简化TCC的使用，通常会将一个服务的某个核心接口拆成两个，比如库存服务的扣减库存接口，拆成两个子接口：①扣减接口 ②回滚扣减库存接口，由TCC框架来保证当某个接口执行失败后去执行对应的rollback接口。
- 总结
- - 从正常的流程上讲，TCC仍然是一个两阶段提交协议。但是，在执行出现问题的时候，有一定的自我修复能力，如果任何一个事务参与者出现了问题，协调者可以通过执行逆操作来取消之前的操作，达到最终的一致状态（比如冲正交易、查询交易）。
  - 从TCC的执行流程也可以看出，服务提供方需要提供额外的补偿逻辑，那么原来一个服务接口，引入TCC后可能要改造成3种逻辑：
  - - Try：先是服务调用链路依次执行Try逻辑；
    - Confirm：如果都正常的话，TCC分布式事务框架推进执行Confirm逻辑，完成整个事务；
    - Cancel：如果某个服务的Try逻辑有问题，TCC分布式事务框架感知到之后就会推进执行各个服务的Cancel逻辑，撤销之前执行的各种操作。
  - 注意：在设计TCC事务时，接口的Cancel和Confirm操作都必须满足幂等设计。
  - 框架选型
  - - TCC框架的可供选择余地比较少，目前相对比较成熟的是阿里开源的分布式事务框架seata（[https://github.com/seata/seata](https://link.zhihu.com/?target=https%3A//github.com/seata/seata)），这个框架是经历过阿里生产环境的大量考验，同时也支持dubbo、spring cloud。
  - 优点
  - - 跟2PC比起来，实现以及流程相对简单了一些，但数据的一致性比2PC也要差一些，当然性能也可以得到提升。
  - 缺点
  - - TCC模型对业务的侵入性太强，事务回滚实际上就是自己写业务代码来进行回滚和补偿，改造的难度大。一般来说支付、交易等核心业务场景，可能会用TCC来严格保证分布式事务的一致性，要么全部成功，要么全部自动回滚。这些业务场景都是整个公司的核心业务有，比如银行核心主机的账务系统，不容半点差池。
    - 但是，在一般的业务场景下，尽量别没事就用TCC作为分布式事务的解决方案，因为自己手写回滚/补偿逻辑，会造成业务代码臃肿且很难维护。

#### 4.可靠性消息的最终一致性

如rocketmq的半消息 + 事务回查

#### 5.定期校对





# 分布式事务

保证关系型数据库分布式数据一致性

## XA

XA协议由Tuxedo首先提出的，并交给X/Open组织，作为[资源管理器](https://baike.baidu.com/item/资源管理器/1951545)（数据库）与[事务](https://baike.baidu.com/item/事务)管理器的接口标准。[Oracle](https://baike.baidu.com/item/Oracle/301207)、[Informix](https://baike.baidu.com/item/Informix/269954)、[DB2](https://baike.baidu.com/item/DB2/7034285)和[Sybase](https://baike.baidu.com/item/Sybase/2138155)等各大数据库厂家都提供对XA的支持。XA协议采用两阶段提交方式来管理[分布式事务](https://baike.baidu.com/item/分布式事务/4747029)。XA接口提供资源管理器与事务管理器之间进行通信的标准接口。XA协议包括两套函数，以xa_开头的及以ax_开头的。

二阶提交

#### AP

应用程序。比如我们的JAVA应用

#### TM

事务协调者。比如我们的SEATA框架

#### RM

资源管理者。比如Mysql、Oracle



### Mysql

mysql支持XA协议文档https://dev.mysql.com/doc/refman/8.0/en/xa.html

#### 13.3.8.1 XA Transaction SQL Statements

To perform XA transactions in MySQL, use the following statements:

```sql
#第一阶段
#开启一个xid的事务
XA {START|BEGIN} xid [JOIN|RESUME]
执行sql语句
#结束一个xid的事务
XA END xid [SUSPEND [FOR MIGRATE]]
#向TM表明已经准备好了
XA PREPARE xid

#第二阶段
#提交事务
XA COMMIT xid [ONE PHASE]
#回滚事务
XA ROLLBACK xid

XA RECOVER [CONVERT XID]
```



例子如下，两个不同机器上的mysql数据库为例

oms_db

```sql
XA START 'TEST01';
INSERT INTO `oms_db`.`oms_order_main` ...
XA END 'TEST01';
XA PREPARE 'TEST01';

##由TM来决定，事务是该提交还是回滚
XA ROLLBACK 'TEST01';
```

order_main

```sql
XA START 'TEST02';
INSERT INTO order_main ...
XA END 'TEST02';
XA PREPARE 'TEST02';

##由TM来决定，事务是该提交还是回滚
XA ROLLBACK 'TEST02';
```

**TM先开启为每一个RM开启事务，RM执行结束后，根据每个RM的执行结果，来决定全局的、也就是第二阶段的提交或回滚**

那么，如果在第二阶段，一个RM执行COMMIT成功了，但是另一个RM执行COMMIT失败了，这是TM需要解决的问题，比如SEATA，需要有重试机制直至二者commit成功



### JTA

JTA，即Java Transaction API，JTA允许应用程序执行分布式事务处理——在两个或多个网络计算机资源上访问并且更新数据。[JDBC](https://baike.baidu.com/item/JDBC)[驱动程序](https://baike.baidu.com/item/驱动程序)的JTA支持极大地增强了数据访问能力。

Java提供了基于XA的应用程序执行分布式事务处理

如rt.jar->javax.sql.XAConnection、XADataSource   javax.transaction.xa.Xid

不同的数据库厂商的实现，比如mysql

```
com.mysql.cj.jdbc.MysqlXAConnection
```



Java虽然提供了相应的实现规范接口，但是如果我们自己实现还是需要考虑比如第二阶段的完全成功，所以引出已经成熟的分布式事务框架如Atomikos、Bitronix、Seata

Atomikos不是独立部署的中间件，只是一个jar包，那么就需要当前项目把所有的数据源集成进来

Seata是独立部署的中间件

## Seata

### AT模式

#### 写隔离

- 一阶段本地事务提交前，需要确保先拿到 **全局锁** 。
- 拿不到 **全局锁** ，不能提交本地事务。
- 拿 **全局锁** 的尝试被限制在一定范围内，超出范围将放弃，并回滚本地事务，释放本地锁。





### TCC模式



### SAGA模式



### XA模式



# Zookeeper

## Zookeeper的作用

### 分布式协调框架

协调了什么？协调了分布式环境下各个节点访问顺序一致性

如：Kafka选master

### 配置中心

**存储**：如：/bibabo/stock/stock-ws.properties里面的nodedata就是配置详情

**配置修改动态感知**：开发或运维人员修改set /bibabo/stock/stock-ws.properties 10086

客户端Wacther机制监听事件回调，拿到修改后的值

### 注册中心

**存储**：服务端启动成功创建临时节点，如：/bibabo/dubbo/stock/providers -> dubbo://192.168....																										   				同级另一个dubbo://192.169....

服务端下线，心跳检测失败，临时节点会删除

**服务动态上下线感知**：Wacther机制监听/bibabo/dubbo/stock/providers的子节点，发生变更则刷新地址列表

### 分布式锁

1. 多台客户端并发向Zookeeper写入节点，第一个写入成功的节点，即获得分布式锁
2. 后续的节点与第一个节点同级，通过watcher机制依次监听前一个节点的删除事件
3. 获得锁的客户端处理完业务请求后，释放分布式锁，即删除节点
4. 后一个节点收到监听事件回调，获取锁成功

## Wacther机制

push还是pull？

Zookeeper是通过push的机制将变化通知给订阅者，**push机制必须维持一个会话否则zookeeper找不到客户端**，这个会话是一个长连接，Zookeeper中使用SessionManager用来管理会话，向客户端发送心跳包来维持会话。

一次watcher的生命周期：（如果想一直监听，需要循环注册）

> 1.注册
>
> 2.事件回调后，监听完成

## Zookeeper是如何保证CP的

Zab算法

**Zookeeper集群的数据，并不是强一致的，但却保证了CP，为什么**

Leader、Follower、Observer

Leader：所有事务型操作都会转发到Leader节点上处理

Follower：读操作可以由Follower节点处理。参与投票

Observer：只处理读操作。不参与投票，只提升性能用

### 数据同步

1.客户端发起请求，如果是事务请求，必须分发到Leader节点

2.Leader节点将事务请求数据传递给所有的Follower节点

3.Follower节点接收到请求后，会在磁盘记录一条事务日志，但未提交

4.Follower节点写入事务日志成功后，返回ack给到Leader节点

5.Leader节点收到ack后，决策，是否收到的成功ack大于半数节点

​	如果大于，则认为事务成功，返回客户端成功

​	否则则认为事务失败，返回客户端失败

6.成功则commit，失败则rollback

7.如果6同步失败，则通过心跳机制，检测数据一致性，不一致则同步

#### 2PC二阶段提交

需要第一阶段的所有节点返回成功，第二阶段才commit，否则rollback

### 节点的元数据

查看元数据

```zookeeper
stat /damon/age 
```

```text
cZxid = 0x3  //节点被创建的事务zxid
ctime = Thu Mar 09 16:35:32 CST 2023 //创建的时间 
mZxid = 0x3 //修改的事务zxid
mtime = Thu Mar 09 16:35:32 CST 2023 //修改的时间
pZxid = 0x3 //子节点列表中最后一次被修改的zxid
cversion = 0 //子节点的版本号 
dataVersion = 2 //当前节点数据版本号 可是通过版本号实现乐观锁 get /damon/age的dataVersion=2 								set -v 1 /damon/age 17会失败set -v 2 /damon/age 17会成功
aclVersion = 0 //权限版本号
ephemeralOwner = 0x0 //临时节点的所属会话，当前会话结束会删除这个临时节点 
dataLength = 2 //数据长度
numChildren = 0 //子节点数量
```

## 集群

1.集群的每台机器zoo.cfg配置

```properties
tickTime=2000
dataDir=/data/zookeeper/data
clientPort=2181
initLimit=5
syncLimit=2
#2888代表数据同步的端口号 3888代表leader选举的端口号
server.1=zoo1:2888:3888 
server.2=zoo2:2888:3888
server.3=zoo3:2888:3888
```

2.每台机器在dataDir=/data/zookeeper/data下配置myid，myid的值为1-255代表当前zk服务的id

```shell
sh zkServer.sh status
```



## 面试题

1. 什么是Zookeeper？谈谈你对Zookeeper的认识？
   Zookeeper是一个分布式的，开放源代码的分布式应用程序协调服务。它是一个为分布式应用提供一致性服务的软件，提供的功能包括：配置维护、域名服务、分布式同步、组服务等。
2. Zookeeper的核心功能？
   Zookeeper提供了三个核心功能：文件系统、通知机制和集群管理机制。
3. 文件系统
   Zookeeper存储数据的结构，类似于一个文件系统。每个节点称之为znode，买个znode都是类似于K-V的结构，每个节点的名字相当于key，每个节点中都保存了对应的数据，类似于key-value中的value。
4. 通知机制
   当某个client监听某个节点时，当该节点发生变化时，zookeeper就会通知监听该节点的客户端，后续根据客户端的处理逻辑进行处理。
5. 集群管理机制
   zookeeper本身是一个集群结构，有一个leader节点，负责写请求，多个follower节点负责相应读请求。并且在leader节点故障的时候，会根据选举机制从剩下的follower中选举出新的leader。
6. Zookeeper中的角色都有哪些？
7. leader
   处理所有的事务请求（写请求），可以处理读请求，集群中只能有一个leader。
8. follower
   只能处理读请求，同时作为leader的候选节点，即如果leader宕机，follower节点要参与到新的leader选举中，有可能成为新的leader节点。
9. observer
   只能处理读请求，不能参与选举。
10. Zookeeper中的节点有哪几种，分别有什么不同？
    Zookeeper中的几点一共分为7中，分别是持久节点（PERSISTENT）、持久顺序节点（PERSISTENT_SEQUENTIAL）、临时节点（EPHEMERAL）、临时顺序节点（EPHEMERAL_SEQUENTIAL）、容器节点（CONTAINER）、带过期时间的持久节点（PERSISTENT_WITH_TTL）、带过期时间的持久顺序节点（PERSISTENT_SEQUENTIAL_WITH_TTL）。
11. 持久节点（PERSISTENT）
    持久节点，一旦创建成功不会被删除，除非客户端主动发起删除请求。
12. 持久顺序节点（PERSISTENT_SEQUENTIAL）
    持久顺序节点，会在用户路径后面拼接一个不会重复的自增数字后缀，一旦创建成功不会被删除，除非客户端主动发起请求。
13. 临时节点（EPHEMERAL）
    临时节点，当创建该节点的客户端断开连接后就会被自动删除。
14. 临时顺序节点（EPHEMERAL_SEQUENTIAL）
    临时顺序节点，创建时会在用户路径后面拼接一个不会重复的自增数字后缀，当创建该节点的客户端断开连接后就会被自动删除。
15. 容器节点（CONTAINER）
    容器节点，一旦子节点被删除完，该节点就会被服务端自动删除。
16. 带过期时间的持久节点（PERSISTENT_WITH_TTL）
    带过期时间的持久节点，带有超时时间的节点，如果超时时间内没有子节点被创建，就会被删除。需要开启服务端配置extendedTypesEnabled=true。
17. 带过期时间的持久顺序节点（PERSISTENT_SEQUENTIAL_WITH_TTL）
    带过期时间的持久顺序节点，创建节点时会在用户路径后面拼接一个不会重复的自增数字后缀，带有超时时间，如果超时时间内没有子节点被创建，就会被删除。需要开启服务端配置extendedTypesEnabled=true。
18. Zookeeper的工作原理
    Zookeeper的核心是原子广播，这个机制保证了各个Server之前的同步。实现这个机制的协议叫做Zab协议。Zab协议有两种模式，分别是恢复模式（选主）和广播模式（同步）。当服务启动或者在leader崩溃后，Zab就进入了恢复模式，当leader被选举出来，且大多数Server完成了和leader的状态同步后，恢复模式就结束了。状态同步保证了leader和server具有相同的系统状态。之后进入广播模式，如果这个时候当一个server加入到Zookeeper服务中，它会在恢复模式下启动，发现leader，并和leader进行状态同步。等同步结束，它也参与消息广播。Zookeeper服务一直维持在Broadcast状态，直到leader崩溃或者leader失去了大部分followers的支持。
19. Zookeeper是如何保证事务的顺序一致性的？
    Zookeeper采用了递增的事务Id来标识，所有的proposal（提议）都在被提出时加上了zxid，zxid实际上是一个64位的数字，高32位是epoch（纪元）用来标识leader是否发生改变，如果有新的leader产生出来，epoch会自增，低32位用来递增计数。当新产生proposal时，会依赖数据库的两阶段过程，首先会向其他的server发出事务执行请求，如果超过半数的机器都能执行并且能够成功，那么久开始执行。
20. Zookeeper下的server的工作状态？
    每个Server在工作过程中有三种状态：

LOKKING：竞选状态，当前Server不知道leader是谁，正在搜寻
LEADER：领导者状态，当前Server即为选举出来的leader
FOLLOWING：随从状态，leader已经选举出来，当前Server与之同步
OBSERVING：观察状态，同步leader状态，不参与投票

8. 集群中为什么需要leader？
   在分布式环境中，有些业务逻辑只需要集群中的某一台机器执行，其他的机器可以共享这个结果，这样可以大大减少重复计算，提高性能，于是就需要进行leader选举。
9. Zookeeper节点宕机怎么处理？
   Zookeeper本身也是集群，推荐配置不少于3个服务。Zookeeper自身也要保证当一个节点宕机时，其他节点会继续提供服务。

如果是一个Follower宕机，还有2台服务器提供访问，因为Zookeeper上的数据是有多个副本的，数据并不会丢失；如果是一个Leader宕机，Zookeeper会选举出新的Leader。

Zookeeper集群的机制是只要超过半数的节点正常，集群就能正常提供服务。只有在Zookeeper节点挂的太多，只剩一半或者一半不到的节点能工作时，集群才会失效。

10. Zookeeper是如何选择leader节点的？
    当leader崩溃或者leader失去大多数的follower，这时Zookeeper集群进入恢复模式，恢复模式需要重新选举一个leader，让所有的Server都恢复到一个正确的状态。Zookeeper的选举算法有两种：一种是基于basic paxos实现的，另一种是基于fast paxos算法实现的。系统默认的选举算法为fast paxos。Zookeeper集群选举leader节点，有两种情况：①集群刚刚启动时；②当原有的leader节点崩溃时。

部分名词解释：

1服务器id：myid（或sid，集群模式下必有该配置项）
2事务id：服务器中存放的最大zxid
3逻辑时钟：发起的投票轮数计数，用来怕判断多个投票是否在同一轮选举周期中，该值在服务端是一个自增序列。

无论对于那种情况选举leader，只要逻辑时钟不是最新的，这个Server的投票会被清除。

1. 服务器启动时期的Leader选举
   每个Server发出一个投票。由于是初始情况，Server1和Server2都会将自己作为leader服务器来进行投票，每次投票会包含锁推举的服务器的myid和zxid，使用（myid, zxid）表示，此时Server1的投票为（1, 0），Server2的投票为（2, 0），然后各自将这个投票发给集群中其他机器。

接受来自各个服务器的投票。集群的每个服务器收到投票后，首先判断该投票的有效性，如检查逻辑时钟、是否来自于LOOKING状态的服务器。

处理投票。针对每一个投票，服务器都需要将别人的投票和自己的投票进行比较，比较规则如下：

1优先判断zxid。zxid（事务ID）比较大的服务器优先作为Leader。
2如果zxid相同，那么久比较myid。myid（服务器ID）比较大的服务器作为Leader服务器。

对于Server1而言，它的投票是（1, 0），接收Server2的投票为（2, 0），首先会比较两者的zxid，均为0，在比较myid，此时Server2的myid最大，于是更新自己的投票为（2, 0），然后重新投票，对于Server2而言，不需要更新自己的投票，只是再次向集群中所有机器发出上一次投票信息即可。

统计投票。每次投票后，服务器都会统计投票信息，判断是否已经有过半机器接收到相同的投票信息，对于Server1、Server2恶言，都统计出集群中已经有两台机器接受了（2, 0）的投票信息，此时便认为已经选出了Leader。
改变服务器状态。一旦确定了Leader，每个服务器就会更新自己的状态，如果是Follower，那么就变更为FOLLOWING，如果是Leader，那就变更为LEADING。

2. 服务器运行时期Leader选举
   在Zookeeper运行期间，Leader与非Leader服务器各司其职，即便当有非Leader服务器宕机或者新加入，此时也不影响Leader，但是一旦Leader服务器挂了，那么整个集群将暂停对外服务，进入新一轮Leader选举，其过程和启动时期的Leader选举过程基本一致。假设正在运行的有Server1、Server2、Server3三台服务器，当前Leader是Server2，若某一时刻Leader挂了，此时便开始Leader选举。

变更状态。Leader宕机后，剩下的非Observer服务器都会将自己的服务器状态变更为LOOKING，然后开始进入Leader选举过程。
每个Server发出一个投票。在运行期间，每个服务器上的zxid可能不同，此时假定Server1的zxid为111，Server3的zxid为122；在第一轮投票中，Server1和Server2都会投子，产生投票（1, 111)，（3, 122），然后将各自投票发送给集群中所有机器。
接收来自各个服务器的投票。与启动时过程相同。
处理投票。与启动时过程相同，此时，Server3会成为Leader。
统计投票。与启动过程相同。
改变服务器状态。与启动过程相同。

# Redis

1kb等于1024字节

1字节8比特位

分布式缓存

C语言写的

0-15 16个分区

单线程、无线程安全问题

### 五种数据类型

#### String

可以存储 字符串、整数、浮点

整数：可以使用incr()原子递增

##### 实战：1.作计数器，比如修改订单状态里，妥投和拒收两种状态可以相互更改，修改状态成功后，需要处理后续得流程，比如妥投要推结算，三方订单妥投或拒收要mq发送给三方系统，使用incr()，可以作幂等、可以作并发控制   

String类型在Redis底层是使用什么数据结构存储的？

答： int / SDS int存储整型，SDS存储字符和浮点

C语言的字符无法存储二进制，存储字符串'\0'结尾 如果字符串里含有空格 那么空格后面的字符将不会被识别

所以使用SDS sdshdr8  默认长度2^8 - 1  sdshdr 5、8、16、32、64

##### 应用场景：Session共享、keyvalue的缓存比如订单里有春播卡展示卡号

#### List

Redis底层是如何存储来实现这种数据类型的？

redis3.2之前使用的是LinkedList（双向链表，内存占用多，插入删除快）和ZipList（存储元素个数少或者长度短，使用压缩链表、连续内存、占用少，插入删除稍慢）

redis3.2开始使用quickList（基于ZipList的双向链表）

quickListNode{

```
	prev;

	next;

	zipList;// 压缩存储空间，提高存储效率这是list（entry1、entry2）

```

}

##### 应用场景：消费队列（左进右出）、栈（左进左出）

#### Hash

key -> value( filed -> value;filed -> value;filed -> value;) 

也是使用链表解决hash碰撞的

##### 应用场景：宅急送快递推tms时，每一天要为其生成一个批次交接单，交接单对象用Map存储

#### Set

不可重复、无序

##### 应用场景：每日单独成箱质检录入爆品、一堆Sku要Set

Redis底层是如何存储来实现这种数据类型的？

intSet hashTable

如果使用hashTable时，只是用key做存储，value是空的

intset只存储整数类型，使用数组顺序存储，查找二分查找

#### SortedSet

key -> value( score -> value )

可以通过score作排序

Redis底层是如何存储来实现这种数据类型的？

ziplist 或者 skiplist + hashtable

##### 应用场景：需要存排名

### 过期时间

像库房详情warehouse这种redis缓存，不需要设置过期时间

其余绝大多数场景都需要设置过期时间

expire(key, 过期时间);

setex(key ,value, 过期时间)

ttl命令查看剩余过期时间

persist 对key持久化 不需要过期了

**删除过期的key的策略**

1.消极方法：

已经过期了，再一次读取的时候会删除

2.积极方法：周期性的从设置了过期时间的key中选择一部分的key进行删除

  (1)随机测试20个带有超时时间的key

  (2) 如果超过25%的key被删除，则重复执行整个流程

### Rdis内存回收策略

当内存达到一定大时，淘汰一些对象

redis.conf

maxmemory-policy 默认是noeviction直接报错

allkeys-lru 所有的key（设置过期时间和没设置过期时间都算上）最少使用的数据淘汰

allkeys-random 所有的key随机淘汰

volatile-random（随机）/lru（最少使用）/ttl（即将过期） 以上都是设置了过期时间的

### Redis为什么单线程性能却很高？

redis的限制在于：内存和网络带宽

性能高是因为使用到了多路复用

### Redis持久化

1.使用redis作Nosql数据库

2.redis出现故障，快速恢复redis

#### RDB（快照）默认、AOF（事务日志）

RDB:当符合【条件】时，会fork一个子进程  生成dump.rdb文件 进行io操作

条件有4种：1.配置规则 redis.conf  save seconds changes  或的关系

```
														 save 900 1

														 save 300 10

														 save 60 10000

				 2.客户端主动save（阻塞所有来自客户端的请求）或者bgsave（异步后台备份）

                 3.客户端flushall 

                4.执行复制操作 master-slave

```

缺点：两次快照的间隔 会出现数据丢失

AOF：事务操作追加到文件、像实时日志一样、记录所有事务行为。效率会低

redis.conf   Append Only no  改为yes 开启

redis支持两种模式同时存在，但是AOF的优先级更高，启动时会直接加载AOF文件

AOF很大的时候会重写，fork子进程重写，重写的过程中，把后续的指令再记录，再合并

操作系统缓存刷到硬盘 默认是1s

dump.rdb 或者 appendonly.aof文件 在服务器启动时 会自动加载到redis里

### Redis的Lua脚本

eval 执行lua脚本

### 发布订阅

pub / sub

Bloomfilter单点内，分布式情况下的新增或删除如何通知到其他节点

## 分布式Redis

### 主从

从节点redis.conf  配置salveof 主ip 主port

主节点宕机后，无法选出新的主节点

Redis中使用外部的哨兵节点帮助Redis主从选主

### 哨兵

1.监控master slave健康情况

2.当master出现故障时，从slave选举一个新的master

#### 哨兵也要作集群

哨兵之间不需要做配置，使用节点订阅pub/sub，订阅redis集群主节点来了解彼此

哨兵集群也要有选leader，使用raft算法

### Cluster

分片用的，一般3个分片，并且对3个分片做salve

### 分布式锁

setnx 不能重复

setnx返回1 设置成功

expire设置带超时时间的

### 缓存雪崩

**现象**：大量key同一时间点失效，同时又有大量请求打进来，导致流量直接打在DB上，造成DB不可用。

**解决方案**：

1.设置key永不失效（热点数据）；

2.设置key缓存失效时候尽可能错开；乘以随机数

3.使用多级缓存机制，比如同时使用redsi和memcache缓存，请求->redis->memcache->db；

### 缓存穿透

Redis和DB都不存在

- 从DB中查询出来数据为空，也进行空数据的缓存，避免DB数据为空也每次都进行数据库查询；
- 使用布隆过滤器，但是会增加一定的复杂度及存在一定的误判率；

前端 调用  wms return 实物库存 - 占用数

把仓库 + 商品id + lot 存入布隆过滤器中

mysql最大连接数**16384**

### 缓存击穿

击穿了redis，但是数据库存在

某一时刻对同一个key有大量的并发请求进来，这时候会出现请求打到数据库层面

解决方案：

1.加分布式锁，对于同一个key，访问redis时加分布式锁，那么大并发情况下，只有一个线程会拿到锁，读DB并且写入缓存，后续排队的线程就可以从缓存中读取了。

再优化

```java
// trylock的时间是很难确定的，需要容忍被击穿的可能
lock.tryLock(100ms);// 假如一时刻数万请求进来，则100ms后，阻塞结束，不需要再排队串行，改为并行
String cache = getStockFromCache();
if (cache == null) {
    cache = getStockFromDb();
}
lock.unlock();

```

2.热点数据不过期

和雪崩的区别在于，雪崩是同一时刻大批量key失效，而击穿是指某一个key失效后多个并发访问



### 数据库与Redis的数据一致性

无法实现强一致性

#### 最终一致的实现

##### 先删除Redis再更新数据库

如果redis删除失败则抛出异常，innodb事务回滚。不会出现问题

如果redis删除成功，但是更新mysql失败，再次读取redis时发现不存在会读数据库，读到的一定是最新的。不会出现问题

**此种处理方式看起来并不会出现数据一致性的问题，但是先删除redis值成功时的临界点，可能出现并发问题导致一致性问题**

线程A先删除redis成功，线程B读取redis为空，则读数据库，读到的是线程A还未更新操作的值(线程A所认为的旧值，而不是线程A所预期的最新值)，线程A再更新数据库成功，但此时redis上的值是不准确的

该问题需要加分布式锁来保证，线程A删除redis与更新数据库操作需要被分布式写锁包裹住，线程B读取需要被分布式读锁包裹住

#### 先更新数据库再更新Redis

如果更新数据库失败，则事务回滚。不会出现问题

如果更新数据库成功，再删除redis失败，此时需要保证一致性，可以采用重试机制

​		1.MQ重试，RocketMQ和Mysql可以保证最终一致性，消费端删除redis来达到Mysql与Redis的最终一致

​		2.本地表重试，删除redis的操作表与Mysql的事务表放到一个事务提交。redis操作表job重试（1s一次也会延			迟1s，容忍的情况可以使用）

​		3.借助mysql的Binlog，比如Canal框架，更新Redis，优解，因为即满足了一定的实时性，又不侵入业务









# 数据库

事务ACID

A:原子性（atomicity，或称不可分割性）

一个事务（transaction）中的所有操作，要么全部完成，要么全部不完成，不会结束在中间某个环节。事务在执行过程中发生错误，会被恢复（Rollback）到事务开始前的状态，就像这个事务从来没有执行过一样。

C:一致性（consistency）

在事务开始之前和事务结束以后，数据库的完整性没有被破坏。这表示写入的资料必须完全符合所有的预设规则，这包含资料的精确度、串联性以及后续数据库可以自发性地完成预定的工作。

I:隔离性（isolation，又称独立性）

数据库允许多个并发事务同时对其数据进行读写和修改的能力，隔离性可以防止多个事务并发执行时由于交叉执行而导致数据的不一致。

事务隔离分为不同级别，包括读未提交（Read uncommitted）、读已提交（read committed）、可重复读（repeatable read）和串行化（Serializable）。

D:持久性（durability）

事务处理结束后，对数据的修改就是永久的，即便系统故障也不会丢失。

## 4种隔离级别分别解决了哪些问题

```
未提交读  脏读、不可重复读、幻读都未解决
已提交读  不可重复读和幻读未解决
可重复读  幻读未解决
串行化    全部解决

```

事务并发存在的问题

```
**脏读**：一个事务读取到了另一个事务未提交的数据操作结果。这是相当危险的，因为很可能所有的操作都被回滚。
**不可重复读**：一个事务对同一行数据重复读取两次，但是却得到了不同的结果。
**幻读**：事务在操作过程中进行两次查询，第二次查询的结果包含了第一次查询中未出现的数据
或者缺少了第一次查询中出现的数据（这里并不要求两次查询的SQL语句相同）。
这是因为在两次查询过程中有另外一个事务插入数据造成的。

```

## Mysql

### InnoDB

InnnoDB默认隔离级别为RR可重复读，正常来说是解决不了幻读的？但InnoDB可以，怎样做到？

#### 锁

##### 行锁



##### 间隙锁



##### 临建锁

#### MVCC

多版本并发控制，只能读取数据行版本号小于等于当前事务版本号，大于删除版本号或为null得数据





# 幂等

在编程中一个幂等操作的特点是其任意多次执行所产生的影响均与一次执行的影响相同

## 保证幂等性的方案

### Redis

1.不存在并发的场景。比如消息的消费

```java
// 发送端代码
// 生成一个唯一ID，例如时间戳，或UUID或token
String uid = UUID...;
Message message = new Message(消息体中附带uid);

// 消费端代码
// 检查消息是否消费过
String val = redisTemplate.get(KEY_PREFIX + UID);
if (val != null) {return "success"};
// 执行本地事务
begin transaction;
// 执行成功后将消息中的uid写入到redis中
redisTemplate.set(KEY_PREFIX + UID);

```

2.存在并发的场景。这种一般是异常情况，同一时刻客户端发送了多次相同的请求。需要加层分布式锁

```java
// 客户端代码
// 生成一个唯一ID，例如时间戳，或UUID
String uid = UUID...;
Message message = new Message(消息体中附带uid);

// 服务端代码
redisTemplate.lock();
// 检查消息是否消费过
String val = redisTemplate.get(KEY_PREFIX + UID);
if (val != null) {return "success"};
// 执行本地事务
begin transaction;
// 执行成功后将消息中的uid写入到redis中
redisTemplate.set(KEY_PREFIX + UID);
redisTemplate.unlock();

```

### 数据库

1.数据库的唯一约束。UNQUE_KEY  insert 抛出DuplicateKeyException。

比如业务上天然的唯一键如orderId skuId

非天然的。服务端创建一个消息表，基于消息生成MD5作为唯一键做插入，插入成功则处理，异常则认为被幂等校验了

