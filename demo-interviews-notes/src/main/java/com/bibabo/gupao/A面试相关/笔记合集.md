1kb等于1024字节

1字节8比特位

# Redis

分布式缓存

C语言写的

0-15 16个分区

单线程、无线程安全问题

### 五种数据类型

#### String

可以存储 字符串、整数、浮点

整数：可以使用incr()原子递增

##### 		实战：1.作计数器，比如修改订单状态里，妥投和拒收两种状态可以相互更改，修改状态成功后，需要处理后续得流程，比如妥投要推结算，三方订单妥投或拒收要mq发送给三方系统，使用incr()，可以作幂等、可以作并发控制   

String类型在Redis底层是使用什么数据结构存储的？

答： int / SDS int存储整型，SDS存储字符和浮点

C语言的字符无法存储二进制，存储字符串'\0'结尾 如果字符串里含有空格 那么空格后面的字符将不会被识别

所以使用SDS sdshdr8  默认长度2^8 - 1  sdshdr 5、8、16、32、64

##### 应用场景：Session共享、keyvalue的缓存比如订单里有春播卡展示卡号

#### List

Redis底层是如何存储来实现这种数据类型的？

redis3.2之前使用的是LinkedList（双向链表，内存占用多，插入删除快）和ZipList（存储元素个数少或者长度短，使用压缩链表、连续内存、占用少，插入删除稍慢）

redis3.2开始使用quickList（基于ZipList的双向链表）

quickListNode{

​		prev;

​		next;

​    	zipList;// 压缩存储空间，提高存储效率这是list（entry1、entry2）

}

##### 应用场景：消费队列（左进右出）、栈（左进左出）

#### Hash

key -> value( filed -> value;filed -> value;filed -> value;) 

也是使用链表解决hash碰撞的

##### 应用场景：宅急送快递推tms时，每一天要为其生成一个批次交接单，交接单对象用Map存储

#### Set

不可重复、无序

##### 应用场景：每日单独成箱质检录入爆品、一堆Sku要Set

Redis底层是如何存储来实现这种数据类型的？

intSet hashTable

如果使用hashTable时，只是用key做存储，value是空的

intset只存储整数类型，使用数组顺序存储，查找二分查找

#### SortedSet

key -> value( score -> value )

可以通过score作排序

Redis底层是如何存储来实现这种数据类型的？

ziplist 或者 skiplist + hashtable

##### 应用场景：需要存排名

### 过期时间

像库房详情warehouse这种redis缓存，不需要设置过期时间

其余绝大多数场景都需要设置过期时间

expire(key, 过期时间);

setex(key ,value, 过期时间)

ttl命令查看剩余过期时间

persist 对key持久化 不需要过期了

**删除过期的key的策略**

1.消极方法：

已经过期了，再一次读取的时候会删除

2.积极方法：周期性的从设置了过期时间的key中选择一部分的key进行删除

  (1)随机测试20个带有超时时间的key

  (2) 如果超过25%的key被删除，则重复执行整个流程

### Rdis内存回收策略

当内存达到一定大时，淘汰一些对象

redis.conf

maxmemory-policy 默认是noeviction直接报错

allkeys-lru 所有的key（设置过期时间和没设置过期时间都算上）最少使用的数据淘汰

allkeys-random 所有的key随机淘汰

volatile-random（随机）/lru（最少使用）/ttl（即将过期） 以上都是设置了过期时间的

### Redis为什么单线程性能却很高？

redis的限制在于：内存和网络带宽

性能高是因为使用到了多路复用

### Redis持久化

1.使用redis作Nosql数据库

2.redis出现故障，快速恢复redis

#### RDB（快照）默认、AOF（事务日志）

RDB:当符合【条件】时，会fork一个子进程  生成dump.rdb文件 进行io操作

条件有4种：1.配置规则 redis.conf  save seconds changes  或的关系

​															 save 900 1

​															 save 300 10

​															 save 60 10000

​					 2.客户端主动save（阻塞所有来自客户端的请求）或者bgsave（异步后台备份）

​                     3.客户端flushall 

​                    4.执行复制操作 master-slave

缺点：两次快照的间隔 会出现数据丢失

AOF：事务操作追加到文件、像实时日志一样、记录所有事务行为。效率会低

redis.conf   Append Only no  改为yes 开启

redis支持两种模式同时存在，但是AOF的优先级更高，启动时会直接加载AOF文件

AOF很大的时候会重写，fork子进程重写，重写的过程中，把后续的指令再记录，再合并

操作系统缓存刷到硬盘 默认是1s

dump.rdb 或者 appendonly.aof文件 在服务器启动时 会自动加载到redis里

### Redis的Lua脚本

eval 执行lua脚本

### 发布订阅

pub / sub

Bloomfilter单点内，分布式情况下的新增或删除如何通知到其他节点

## 分布式Redis

### 主从

从节点redis.conf  配置salveof 主ip 主port

主节点宕机后，无法选出新的主节点

Redis中使用外部的哨兵节点帮助Redis主从选主

### 哨兵

1.监控master slave健康情况

2.当master出现故障时，从slave选举一个新的master

#### 哨兵也要作集群

哨兵之间不需要做配置，使用节点订阅pub/sub，订阅redis集群主节点来了解彼此

哨兵集群也要有选leader，使用raft算法

### Cluster

分片用的，一般3个分片，并且对3个分片做salve

### 分布式锁

setnx 不能重复

setnx返回1 设置成功

expire设置带超时时间的

### 缓存雪崩

**现象**：大量key同一时间点失效，同时又有大量请求打进来，导致流量直接打在DB上，造成DB不可用。

**解决方案**：

1.设置key永不失效（热点数据）；

2.设置key缓存失效时候尽可能错开；乘以随机数

3.使用多级缓存机制，比如同时使用redsi和memcache缓存，请求->redis->memcache->db；

### 缓存穿透

Redis和DB都不存在

- 从DB中查询出来数据为空，也进行空数据的缓存，避免DB数据为空也每次都进行数据库查询；
- 使用布隆过滤器，但是会增加一定的复杂度及存在一定的误判率；

前端 调用  wms return 实物库存 - 占用数

把仓库 + 商品id + lot 存入布隆过滤器中

### 缓存击穿

击穿了redis，但是数据库存在

某一时刻对同一个key有大量的并发请求进来，这时候会出现请求打到数据库层面

解决方案：

1.加分布式锁，对于同一个key，访问redis时加分布式锁，那么大并发情况下，只有一个线程会拿到锁，读DB并且写入缓存，后续排队的线程就可以从缓存中读取了

2.热点数据不过期

和雪崩的区别在于，雪崩是同一时刻大批量key失效，而击穿是指某一个key失效后多个并发访问



# Zookeeper

分布式协调框架

协调什么？分布式架构下的所有需要协调的应用节点

master选举，顺序写入，注册中心（服务管理，服务上下线感知），配置中心（key文件名 value文件详情）

类似目录存储

### 节点特性

临时节点（生命周期为一个会话）（服务上下线感知，provider挂掉了，zookeeper心跳检测他挂了，临时节点删除，consumer注册watcher这个节点，通知consumer，长连接）

​		临时节点不可存在子节点

有序节点、持久化节点

​		必须现有父节点，再有子节点

​		同级节点下，节点名称必须唯一

#### 有序节点

全局ID

#### 同级节点唯一性

master选举、分布式锁



#### stat查看元数据



### 分布式锁

#### 1.同级节点唯一性

分布式多应用节点共同写入一个锁临时节点，第一个写入成功的获得锁，释放锁时会话关闭或者删除节点，其余节点watcher监听，再去竞争写入（惊群）

#### 2.临时有序节点

/lock-0001  /lock-0002  /lock-0003

3监听2 2监听1

## 集群

Leader

Follower

Obsever 不参与事务请求和leader选举的投票 也和leader同步数据 提供服务

### 如何集群内部数据的一致性？

### 答：ZAB协议(zookeeper 原子广播)

ZAB（Zookeeper Atomic Broadcast） 协议是为分布式协调服务 ZooKeeper 专门设计的一种支持崩溃恢复的原子广播协议。在 ZooKeeper 中，主要依赖 ZAB 协议来实现分布式数据一致性，基于该协议，ZooKeeper 实现了一种主备模式的系统架构来保持集群中各个副本之间的数据一致性。通过单一的主进程来接收并处理客户端的所有事务请求。

ZAB协议包含两种基本模式：**崩溃恢复和消息广播**

#### 崩溃恢复模式

ZAB 协议的这个基于原子广播协议的消息广播过程，在正常情况下是没有任何问题的，但是一旦 Leader 节点崩溃，或者由于网络问题导致 Leader 服务器失去了过半Follower 节点的联系（leader 失去与过半 follower 节点联系，可能是 leader 节点和 follower 节点之间产生了网络分区，那么此时的 leader 不再是合法的 leader 了），那么就会进入到崩溃恢复模式。在 ZAB 协议中，为了保证程序的正确运行，整个恢复过程结束后需要选举出一个新的Leader。

1. 已经被处理的消息不能丢失
2. 被丢弃的消息不能再次出现

#### 消息广播模式

消息广播的过程实际上是一个简化版本的二阶段提交过程

leader 接收到消息请求后，将消息赋予一个全局唯一的64 位自增 id，叫：zxid，通过 zxid 的大小比较既可以实现因果有序这个特征
leader 为每个 follower 准备了一个 FIFO 队列（通过 TCP协议来实现，以实现了全局有序这一个特点）将带有 zxid的消息作为一个提案（proposal）分发给所有的 follower
当 follower 接收到 proposal，先把 proposal 写到磁盘，写入成功以后再向 leader 回复一个 ack
当 leader 接收到合法数量（超过半数节点）的 ACK 后，leader 就会向这些 follower 发送 commit 命令，同时会在本地执行该消息
当 follower 收到消息的 commit 命令以后，会提交该消息
   leader 的投票过程，不需要 Observer 的 ack，也就是Observer 不需要参与投票过程，但是 Observer 必须要同步 Leader 的数据从而在处理请求的时候保证数据的一致性



## ZookeeperOrRedis分布式锁应用场景

1.数据库层面：数据库中没有你想要进行加锁的行记录

假如一个订单可以存在多个销退单，但是某种特殊情况下我只希望存在唯一的销退单，并且有可能先根据orderId查询，不存在则并发插入。此时就无法使用数据库层面的锁机制了，只能抽出数据库层面高一个维度加分布式锁

2.非数据库层面，如redis的并发插入

缓存击穿，同一时刻key不存在，需要加锁，第一个拿到锁的线程获取之后写入redis，后续则都会从redis读取

业务中一天打印一个批次交接单，如果在不存在的情况下，并发获取不到，写入的时候只有最后成功的存在了，不成功的都消失了







# Mysql

存储引擎是插拔式的

5.5以前默认是Mysaim

5.5开始使用InnoDb

#### 索引是什么？

索引是为了加速对表中数据行的检索而创建的一种分散存储的**数据结构**

硬盘级的

#### 为什么不用平衡二叉查找树？

1.树太深了，O（logn）

2.每个节点存储太小了，比如varchar（64），一次IO操作系统一页4kb，mysql默认读16k，一个关键字64字节加上两个引用，肯定达不到16

k，浪费了一次IO

#### B-Tree多路平衡查找树

绝对平衡，子节点都在同一高度

1.树变矮了

2.一次IO读取的足够多了

为了维护树的平衡，插入时会调整树，所以索引不宜建多不冗余

##### Mysql的索引是几路平衡查找树？

取决于你建索引的关键字的大小，越小路越多，路越多树越矮

#### B+Tree

1.左闭合区间，比如找1，也要找到树的叶子节点

2.非叶子节点不保存数据，只保存关键字和引用

3.叶子节点保存数据

4.叶子节点数据区是有顺序的 天然排序

##### 优点

1.随机IO 变为顺序IO

2.非叶子节点不保存数据，磁盘读写更多，树更矮了

3.排序能力强

4.B+树查询更加稳定



#### Mysaim引擎和InnoDB引擎

##### Mysaim是每一种索引的叶子节点也就是数据区，都存储表数据对应的地址

表级锁

##### InnoDB的主键索引的叶子节点也就是数据区，直接存储数据，其余的辅助索引的叶子节点存储的都是主键索引的关键字

行级锁

InnoDB，如果没有主键，就找唯一主键作为主键，没有唯一键默认生成6位int型主键

##### CSV存储引擎  1.数据的快速导入导出   2.表格直接生成csv文件

##### Archive存储引擎  大数据量，数据压缩

##### Memory存储引擎  数据存储在内存（临时表）

#### 索引的离散性要高

#### 最左匹配原则

对索引中关键字进行计算（对比），一定是从左往右依次进行的，且不可跳过

创建数据库时可以选择  **排序规则** ASCII码

#### 普通索引



#### 主键索引

id

#### 唯一索引

#### 联合索引

1.经常用的列优先（最左匹配原则）  2.离散性高的列优先  3.宽度小的列优先

##### 覆盖索引

如果查询的列可以通过索引节点中的关键字直接返回，则该索引称之为覆盖索引

##### 实战

1.select * from wms_inv where sku_id = 2014565 and ware_id = 1;

2.select sku_id,ware_id,lot;// 

库房的wms_inv表创建一个联合索引，wms_Inv_id，sku_id，ware_id，lot

wms_Inv_id是逻辑主键，建唯一索引

sku_id + ware_id为联合索引，1,2sql都能命中

现在的InnoDB比较智能，颠倒顺序也可以命中索引



##### mysql客户端与服务端的通信方式是“半双工”

半双工指两边可以互相通信，但是某一时刻只会有一个人在讲话

全双工，两人可以同一时刻一起讲话

单工只能一方对另一方讲话

#### explain

##### type All全表扫 < index 基于索引进行全索引扫描（比如命中覆盖索引） <  range（like索引）  < ref < const唯一索引或主键索引

## 事务

一组不可分割的操作集合，数据库操作的最小操作单元

show VARIABLES like ‘autoCommit’

autoCommit 默认为ON

```java
connection.setAutocommit(false)// 关闭自动提交 要手动提交事务
......
commit()
```

### ACID

Atomic：要么一起成功、要么一起失败

Consist：数据要满足预期

Isolation：一个事务提交之前，对其他事务的是不可见的

Durability：事务做出的修改要永久保存

### 其中隔离性会因为并发事务产生以下问题

脏读：事务A修改未提交，事务B读到A事务未提交的值

不可重复读：事务A第一次读取，事务B修改，事务A二次读取时值发生了变化

**前两个是指定莫一行记录读取**  **幻读是指读取多行记录**

幻读：事务A第一次范围读取，只读到两条记录，事务B插入一条未提交，事务A第二次读取读到了三条记录

### 事务隔离级别标准

未提交读：什么问题都没解决

已提交读：解决脏读

可重复读：解决不可重读

串行化：解决幻读

InnoDB默认是可重复读级别，但是解决了幻读的问题

## InnoDB是如何实现事务隔离级别标准的？锁和MVCC

### 锁

innoDB的行锁是通过对索引上的索引项加锁实现的

只有通过索引条件进行数据检索，才会使用行级锁，否则使用表锁（InnoDB的表锁是通过锁住所有行实现的）

假如id是主键索引，name是二级索引辅助索引，如果update的where条件是name过滤的话，那么会先在二级索引上加锁，然后再到找到二级索引的数据区也就是找到主键索引 在主键索引上加锁。会加两把锁

##### 1.共享锁（行锁）

lock in Share mode

一个事务获取到共享锁，其他事务也可以获取到这个共享锁，但不可以获取排他锁

##### 2.排他锁（行锁）

for update

一个是事务获取到排他锁 其他事务不能获取排他锁或共享锁

##### 3.意向共享锁（表锁）

在获取共享锁之前，必须先获得意向共享锁，一把意向共享锁可以被多个事务共持有

##### 4.意向排他锁（表锁）

在获取排他锁之前，必须先获得意向排他锁，一把意向排他锁可以被多个事务共持有

意向锁的作用？当有事务想锁表时，需要判断意向锁是否存在，必须等意向锁释放才能锁表

##### 5.自增锁

对于自增列自增长的一个特殊的表级别锁

show variables like 'innodb_autoinc_lock_mode';

默认自增值为1，事务未提交ID永久丢失

##### 行锁的算法

 1 4 6 7 10 

会分为6个区间 (-~ , 1]、(1 , 4]、( 4, 6 ]、( 6, 7 ]、( 7, 10 ]、(10 , +~]

##### 记录锁 record lock

唯一索引或者主键索引，查询条件是精准匹配，退化为Record锁

select * from user where id =4 for update

**ps：如果是可重复的普通索引，锁的是（1 ， 6）1-6开区间锁住**

##### 间隙锁 gap lock

命中索引后，记录不存在，那么临建锁会退化为Gap锁，也就是只锁一个区间

select * from user where id = 5 for update

( 4, 6 )锁住这个区间 左开右开

**只在RR隔离界别存在**

##### 临键锁（默认行锁算法）next-key lock = gap lock + record lock

select * from user where id > 5 and id < 9 for update;

命中索引后，记录存在6 7  锁住的是记录的当前区间和下一个区间( 4, 6 ]、( 6, 7 ]、( 7, 10 ]，如果现在另一个事务插入8是插不进去的，那么当前事务再次读取的时候，就不会出现幻读



##### 1.如何用锁解决脏读？

读加共享锁，改加排他锁

##### 2.如何用锁解决不可重复读？

读加共享锁，改加排他锁

##### 3.如何用锁解决幻读？

读加排他锁，默认是临建锁，nextkey锁  锁住当前记录所在区间和下一个区间，这样就可以解决幻读

#### 死锁

死锁的避免

1.固定顺序的访问表和行

2.大事务拆小

3.如果业务允许，降低事务隔离级别  因为间隙锁和临建锁 只存在RR隔离级别，所以降低隔离级别后，就不会锁住区间了，锁的粒度就变小了

4.建立合理的索引 尽量避免表锁

默认事务隔离级别就是RR 可重复读

##### 当前读使用临建锁解决幻读、快照读使用MVCC解决幻读

### MVCC(多版本并发控制)

Mutiversion Concurrency Control

对事务内处理的数据做多版本的管理，以达到用来避免写操作的阻塞，从而引发读操作的并发问题

数据行版本号和删除版本号

开起一个事务会分配全局事务id

插入时，数据行版本号为事务id

删除时，删除版本号为事务id

修改时，先把修改的行copy新行，先插入数据行版本号为事务id，再把原行的删除版本号为事务id

查询时，1.找数据行版本号早于当前事务版本号 2.找删除版本号为null或者删除版本号大于当前版本号（小于当前版本号的说明已经删除不要了）



# 多线程

线程优雅退出

1.interrupted标识

2.Daemon守护线程。所有的非守护线程退出，jvm就会退出

(1) thread.setDaemon(true)必须在thread.start()之前设置，否则会跑出一个IllegalThreadStateException异常。你不能把正在运行的常规线程设置为守护线程。
 (2) 在Daemon线程中产生的新线程也是Daemon的。
 (3) 不要认为所有的应用都可以分配给Daemon来进行服务，比如读写操作或者计算逻辑。
 写java多线程程序时，一般比较喜欢用java自带的多线程框架，比如ExecutorService，但是java的线程池会将守护线程转换为用户线程，所以如果要使用后台线程就不能用java的线程池。



# RocketMQ

## 



## 消息的种类

#### 1.同步消息

producer

```
DefaultMQProducer producer = new DefaultMQProducer("please_rename_unique_group_name");
// 设置NameServer的地址
producer.setNamesrvAddr("localhost:9876");
// 启动Producer实例
producer.start();
Message msg = new Message("TopicTest", "Hello RocketMQ").getBytes(RemotingHelper.DEFAULT_CHARSET));
// 发送消息到一个Broker
SendResult sendResult = producer.send(msg);
// 如果不再发送消息，关闭Producer实例。
producer.shutdown();
```

#### 2.异步消息

producer

```
producer.setRetryTimesWhenSendAsyncFailed(0);
producer.send(msg, new SendCallback() {
@Override
public void onSuccess(SendResult sendResult) {
countDownLatch.countDown();
System.out.printf("%-10d OK %s %n", index,
sendResult.getMsgId());
}
@Override
public void onException(Throwable e) {
countDownLatch.countDown();
System.out.printf("%-10d Exception %s %n", index, e);
e.printStackTrace();
}
});
```

#### 3.单向消息

producer

```
// 发送单向消息，没有任何返回结果
producer.sendOneway(msg);
```

#### 4.顺序消息

消息有序指的是一类消息消费时，能按照发送的顺序来消费。例如：一个订单产生了三条消息分别是订单创建、订单付款、订单完成。消费时要按照这个顺序消费才能有意义，但是同时订单之间是可以并行消费的。RocketMQ可以严格的保证消息有序。

消息有序指的是一类消息消费时，能按照发送的顺序来消费。例如：一个订单产生了三条消息分别是订单创建、订单付款、订单完成。消费时要按照这个顺序消费才能有意义，但是同时订单之间是可以并行消费的。RocketMQ可以严格的保证消息有序。

顺序消息分为全局顺序消息与分区顺序消息，全局顺序是指某个Topic下的所有消息都要保证顺序；部分顺序消息只要保证每一组消息被顺序消费即可。

- 全局顺序 对于指定的一个 Topic，所有消息按照严格的先入先出（FIFO）的顺序进行发布和消费。 适用场景：性能要求不高，所有的消息严格按照 FIFO 原则进行消息发布和消费的场景
- 分区顺序 对于指定的一个 Topic，所有消息根据 sharding key 进行区块分区。 同一个分区内的消息按照严格的 FIFO 顺序进行发布和消费。 Sharding key 是顺序消息中用来区分不同分区的关键字段，和普通消息的 Key 是完全不同的概念。 适用场景：性能要求高，以 sharding key 作为分区字段，在同一个区块中严格的按照 FIFO 原则进行消息发布和消费的场景。

producer端

分区顺序：MessageQueueSelector选择发送不同message queue

全局顺序：MessageQueueSelector全部发送同一message queue

根据唯一id取模选择queue发送

```
// 加个时间前缀
           String body = dateStr + " Hello RocketMQ " + orderList.get(i);
           Message msg = new Message("TopicTest", tags[i % tags.length], "KEY" + i, body.getBytes());

           SendResult sendResult = producer.send(msg, new MessageQueueSelector() {
               @Override
               public MessageQueue select(List<MessageQueue> mqs, Message msg, Object arg) {
                   Long id = (Long) arg;  //根据订单id选择发送queue
                   long index = id % mqs.size();
                   return mqs.get((int) index);
               }
           }, orderList.get(i).getOrderId());//订单id

           System.out.println(String.format("SendResult status:%s, queueId:%d, body:%s",
               sendResult.getSendStatus(),
               sendResult.getMessageQueue().getQueueId(),
               body));
```

consumer

```
DefaultMQPushConsumer consumer = new DefaultMQPushConsumer("please_rename_unique_group_name_3");
       consumer.setNamesrvAddr("127.0.0.1:9876");
       /**
        * 设置Consumer第一次启动是从队列头部开始消费还是队列尾部开始消费<br>
        * 如果非第一次启动，那么按照上次消费的位置继续消费
        */
       consumer.setConsumeFromWhere(ConsumeFromWhere.CONSUME_FROM_FIRST_OFFSET);

       consumer.subscribe("TopicTest", "TagA || TagC || TagD");

       consumer.registerMessageListener(new MessageListenerOrderly() {

           Random random = new Random();

           @Override
           public ConsumeOrderlyStatus consumeMessage(List<MessageExt> msgs, ConsumeOrderlyContext context) {
               context.setAutoCommit(true);
               for (MessageExt msg : msgs) {
                   // 可以看到每个queue有唯一的consume线程来消费, 订单对每个queue(分区)有序
                   System.out.println("consumeThread=" + Thread.currentThread().getName() + "queueId=" + msg.getQueueId() + ", content:" + new String(msg.getBody()));
               }

               try {
                   //模拟业务逻辑处理中...
                   TimeUnit.SECONDS.sleep(random.nextInt(10));
               } catch (Exception e) {
                   e.printStackTrace();
               }
               return ConsumeOrderlyStatus.SUCCESS;
           }
       });

       consumer.start();

       System.out.println("Consumer Started.");
```

#### 5.延时消息

producer

```
// 设置延时等级3,这个消息将在10s之后发送(现在只支持固定的几个时间,详看delayTimeLevel)
message.setDelayTimeLevel(3);
// 级别
// org/apache/rocketmq/store/config/MessageStoreConfig.java
private String messageDelayLevel = "1s 5s 10s 30s 1m 2m 3m 4m 5m 6m 7m 8m 9m 10m 20m 30m 1h 2h";
```

#### 6.批量消息

producer

```
String topic = "BatchTest";
List<Message> messages = new ArrayList<>();
messages.add(new Message(topic, "TagA", "OrderID001", "Hello world 0".getBytes()));
messages.add(new Message(topic, "TagA", "OrderID002", "Hello world 1".getBytes()));
messages.add(new Message(topic, "TagA", "OrderID003", "Hello world 2".getBytes()));
try {
   producer.send(messages);
} catch (Exception e) {
   e.printStackTrace();
   //处理error
}
```

#### 7.过滤消息

producer

```
DefaultMQProducer producer = new DefaultMQProducer("please_rename_unique_group_name");
producer.start();
Message msg = new Message("TopicTest",
   tag,
   ("Hello RocketMQ " + i).getBytes(RemotingHelper.DEFAULT_CHARSET)
);
// 设置一些属性
msg.putUserProperty("a", String.valueOf(i));
SendResult sendResult = producer.send(msg);

producer.shutdown();
```

consumer

```
DefaultMQPushConsumer consumer = new DefaultMQPushConsumer("please_rename_unique_group_name_4");
// 只有订阅的消息有这个属性a, a >=0 and a <= 3
consumer.subscribe("TopicTest", MessageSelector.bySql("a between 0 and 3");
consumer.registerMessageListener(new MessageListenerConcurrently() {
   @Override
   public ConsumeConcurrentlyStatus consumeMessage(List<MessageExt> msgs, ConsumeConcurrentlyContext context) {
       return ConsumeConcurrentlyStatus.CONSUME_SUCCESS;
   }
});
consumer.start();
```

#### 8.事务消息

producer

```
public static void main(String[] args) throws MQClientException, InterruptedException {
       TransactionListener transactionListener = new TransactionListenerImpl();
       TransactionMQProducer producer = new TransactionMQProducer("please_rename_unique_group_name");
       ExecutorService executorService = new ThreadPoolExecutor(2, 5, 100, TimeUnit.SECONDS, new ArrayBlockingQueue<Runnable>(2000), new ThreadFactory() {
           @Override
           public Thread newThread(Runnable r) {
               Thread thread = new Thread(r);
               thread.setName("client-transaction-msg-check-thread");
               return thread;
           }
       });
       producer.setExecutorService(executorService);
       producer.setTransactionListener(transactionListener);
       producer.start();
       String[] tags = new String[] {"TagA", "TagB", "TagC", "TagD", "TagE"};
       for (int i = 0; i < 10; i++) {
           try {
               Message msg =
                   new Message("TopicTest1234", tags[i % tags.length], "KEY" + i,
                       ("Hello RocketMQ " + i).getBytes(RemotingHelper.DEFAULT_CHARSET));
               SendResult sendResult = producer.sendMessageInTransaction(msg, null);
               System.out.printf("%s%n", sendResult);
               Thread.sleep(10);
           } catch (MQClientException | UnsupportedEncodingException e) {
               e.printStackTrace();
           }
       }
       for (int i = 0; i < 100000; i++) {
           Thread.sleep(1000);
       }
       producer.shutdown();
   }
```

事务回调监听

```
public class TransactionListenerImpl implements TransactionListener {
  private AtomicInteger transactionIndex = new AtomicInteger(0);
  private ConcurrentHashMap<String, Integer> localTrans = new ConcurrentHashMap<>();
  @Override
  public LocalTransactionState executeLocalTransaction(Message msg, Object arg) {
      int value = transactionIndex.getAndIncrement();
      int status = value % 3;
      localTrans.put(msg.getTransactionId(), status);
      return LocalTransactionState.UNKNOW;
  }
  @Override
  public LocalTransactionState checkLocalTransaction(MessageExt msg) {
      Integer status = localTrans.get(msg.getTransactionId());
      if (null != status) {
          switch (status) {
              case 0:
                  return LocalTransactionState.UNKNOW;
              case 1:
                  return LocalTransactionState.COMMIT_MESSAGE;
              case 2:
                  return LocalTransactionState.ROLLBACK_MESSAGE;
          }
      }
      return LocalTransactionState.COMMIT_MESSAGE;
  }
}
```





# JVM

### JVM参数

堆大小

```
-Xms512m // 初始堆
-Xmx512m // 最大堆
-Xmn192m // 新生代大小
-XX:MetaspaceSize=128m // 元空间
-Xss512k // 栈大小
```

打印gc日志相关

```
-verbose:gc 			// 打印gc信息
-XX:+PrintGCDateStamps  // 打印gc的时间戳
-XX:+PrintGCDetails     // 打印gc详情
-XX:+PrintHeapAtGC      // 打印gc前后堆信息
-XX:+PrintGCApplicationStoppedTime // 打印gc应用线程暂停时间
-Xloggc:E:/logs/gclogs/test_gc_%p_%t.log // 指定日志打印目录，%p指pid，%t指时间戳

-XX:+UseGCLogFileRotation // 打印到多个文件中
-XX:NumberOfGCLogFiles=5 // 最多生成5个文件，满了会循环覆盖第一个文件
-XX:GCLogFileSize=30m  // 每个文件大小
```

oom相关

```
-XX:-HeapDumpOnOutOfMemoryError 
-XX:HeapDumpPath=/data/cs-dubbo-10880/javadump/cs-dubbo-jvmdump.hprof
```

禁用偏向锁

```
-XX:-UseBiasedLocking
```

服务启动的时候真实的分配物理内存给jvm

如果没有此参数，jvm启动的时候，分配的只是虚拟内存，当真正使用的时候才会分配物理内存，代码运行的时候，实时分配物理内存，导致代码运行速度变慢

jvm启动的时候速度会下降很多，如果不在意启动时长可以设置该参数

```
-XX:+AlwaysPreTouch
```

垃圾回收

G1

```
-XX:+UseG1GC

-XX:+PrintAdaptiveSizePolicy // 自适应策略  如果开启 AdaptiveSizePolicy，则每次 GC 后会重新计算 Eden、From 和 To 区的大小，计算依据是 GC 过程中统计的 GC 时间、吞吐量、内存占用量。
因为不是很了解底层原理，先慎用
-XX:G1HeapRegionSize=4m // 堆内存中一个Region的大小
每个Region被标记了E、S、O和H，说明每个Region在运行时都充当了一种角色，其中H是以往算法中没有的，它代表Humongous，这表示这些Region存储的是巨型对象（humongous object，H-obj），当新建对象大小超过Region大小一半时，直接在新的一个或多个连续Region中分配，并标记为H。
-XX:InitiatingHeapOccupancyPercent=30 // 当老年代大小占整个堆大小百分比达到该阈值时，会触发一次mixed gc
-XX:G1ReservePercent=25  // 通过-XX:G1ReservePercent指定G1为分配担保预留的空间比例，默认10%。也就是老年代会预留10%的空间来给新生代的对象晋升，如果经常发生新生代晋升失败而导致Full GC，那么可以适当调高此阈值。但是调高此值同时也意味着降低了老年代的实际可用空间。
-XX:SoftRefLRUPolicyMSPerMB=0
// SoftRefLRUPolicyMSPerMB这个参数大概意思是每1M空闲空间可保持的SoftReference对象的生存时长(单位是ms毫秒)，LRU是Least Recently Used的缩写，最近最少使用的。
这个值jvm默认是1000ms，如果被设置为0，就会导致软引用对象马上被回收掉，进而会导致重新频繁的生成新的类，而无法达到复用的效果。
先慎用
```

CMS

```
-XX:+UseConcMarkSweepGC 
-XX:+ExplicitGCInvokesConcurrentAndUnloadsClasses 
-XX:+CMSScavengeBeforeRemark
```

